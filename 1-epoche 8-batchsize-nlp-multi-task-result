/usr/bin/python3 /home/googler/Desktop/tianchi-multi-task-nlp-main/train.py
---------------------start training-----------------------
[ 1000 - th batch : train acc is: 0.3978978978978979 ; train loss is: 4.64209798876349 ]
[ 2000 - th batch : train acc is: 0.4511630815407704 ; train loss is: 3.6397472146214573 ]
[ 3000 - th batch : train acc is: 0.48282760920306766 ; train loss is: 3.1275911588555934 ]
[ 4000 - th batch : train acc is: 0.5025318829707427 ; train loss is: 2.8204314362469183 ]
[ 5000 - th batch : train acc is: 0.5178785757151431 ; train loss is: 2.6069161002338825 ]
[ 6000 - th batch : train acc is: 0.5287131188531422 ; train loss is: 2.4441126631704804 ]
[ 7000 - th batch : train acc is: 0.5383804829261323 ; train loss is: 2.313432571321304 ]
[ 8000 - th batch : train acc is: 0.5451931491436429 ; train loss is: 2.209034283815555 ]
[ 9000 - th batch : train acc is: 0.5516446271807979 ; train loss is: 2.1233982576014054 ]
[ 10000 - th batch : train acc is: 0.5567681768176818 ; train loss is: 2.0492882649980078 ]
[ 11000 - th batch : train acc is: 0.561573779434494 ; train loss is: 1.9869828812452173 ]
[ 12000 - th batch : train acc is: 0.5640157513126094 ; train loss is: 1.9360204494757516 ]
[ 13000 - th batch : train acc is: 0.5676782829448419 ; train loss is: 1.8878012064218759 ]
[ 14000 - th batch : train acc is: 0.5703085934709622 ; train loss is: 1.8466492396153265 ]
[ 15000 - th batch : train acc is: 0.5732465497699847 ; train loss is: 1.808164485314026 ]
[ 16000 - th batch : train acc is: 0.5751609475592224 ; train loss is: 1.7759287444246776 ]
[ 17000 - th batch : train acc is: 0.5774016118595211 ; train loss is: 1.7457499342226928 ]
0 th epoch train average f1 is: 0.5327423897553438
0 th epoch train ocnli is below:
0.6549371852482201
********************************confusion_matrix********************************
[[11643  3198  1874]
 [ 3862 10523  2899]
 [ 2231  3347 10810]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.66      0.70      0.68     16715
           1       0.62      0.61      0.61     17284
           2       0.69      0.66      0.68     16388

    accuracy                           0.65     50387
   macro avg       0.66      0.66      0.65     50387
weighted avg       0.65      0.65      0.65     50387

0 th epoch train ocemotion is below:
0.4339426959251772
********************************confusion_matrix********************************
[[1224  453   16  434  107 1517   32]
 [ 549 1401   14  540  132 1372   23]
 [  38   35  148   44   35  245    3]
 [ 274  344    9 5481  692 1375   25]
 [ 119  107   11  948 1590  953    6]
 [ 847  650   46 1131  580 8293   21]
 [ 117   91    6  208   51  271   86]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.39      0.32      0.35      3783
           1       0.45      0.35      0.39      4031
           2       0.59      0.27      0.37       548
           3       0.62      0.67      0.65      8200
           4       0.50      0.43      0.46      3734
           5       0.59      0.72      0.65     11568
           6       0.44      0.10      0.17       830

    accuracy                           0.56     32694
   macro avg       0.51      0.41      0.43     32694
weighted avg       0.54      0.56      0.54     32694

0 th epoch train tnews is below:
0.5093472880926343
********************************confusion_matrix********************************
[[ 554  133  204   15   20   22   25   63   14   14   29   59    0   96
    18]
 [  75 2499  440   57  101   34   39  318   90   93  446  136    2  196
    66]
 [ 242  503 3206  278   93   34   73  215  139  107  132  198    0  100
   286]
 [  22  143  456 2941   95   14   96  134   53   74   88  135    0   32
   254]
 [  20  106   79   61 2761  300  205  197 1149   72  143  293   59  384
    52]
 [  26   63   35   17  315 1380   45   99   66    7  152   37    2  113
     9]
 [  31   93  158   68  220   44 2984   87  362  106  260  120    0   82
    60]
 [  43  332  180  115  137   58   51 2320  182   60  110  123    1  120
    51]
 [  13   87  166   61 1434  104  494  310 3155  174   92  185   12  114
   287]
 [  19  159  123   68  105   13  110  117  120 1968   93 1057    0   33
   143]
 [  37  442  151   47  130  147  195  131   79   75 1702  355    0  339
    46]
 [ 113  153  295  106  299   51  128  158  184  918  341 2544    0  119
    61]
 [   0    2    0    1  222    6    0    0    9    0    0    2   45    0
     3]
 [ 100  165   90   18  332  141   76  110   81   30  281   93    1 1700
    13]
 [  22  121  447  222   84   12   79   94  327  148   35   51    0   39
  2190]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.42      0.44      0.43      1266
           1       0.50      0.54      0.52      4592
           2       0.53      0.57      0.55      5606
           3       0.72      0.65      0.68      4537
           4       0.43      0.47      0.45      5881
           5       0.58      0.58      0.58      2366
           6       0.65      0.64      0.64      4675
           7       0.53      0.60      0.56      3883
           8       0.52      0.47      0.50      6688
           9       0.51      0.48      0.49      4128
          10       0.44      0.44      0.44      3876
          11       0.47      0.47      0.47      5470
          12       0.37      0.16      0.22       290
          13       0.49      0.53      0.51      3231
          14       0.62      0.57      0.59      3871

    accuracy                           0.53     60360
   macro avg       0.52      0.51      0.51     60360
weighted avg       0.53      0.53      0.53     60360

0 th epoch dev average f1 is: 0.5861772179035456
0 th epoch dev ocnli is below:
0.7411035029604812
********************************confusion_matrix********************************
[[804 124  83]
 [147 703 151]
 [125 145 718]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.75      0.80      0.77      1011
           1       0.72      0.70      0.71      1001
           2       0.75      0.73      0.74       988

    accuracy                           0.74      3000
   macro avg       0.74      0.74      0.74      3000
weighted avg       0.74      0.74      0.74      3000

0 th epoch dev ocemotion is below:
0.4795474796413389
********************************confusion_matrix********************************
[[178  24   2  28  18  70  12]
 [110 137   3  26  18  68  12]
 [  7   3  17   2   7   9   1]
 [ 55  23   2 532  98  62   9]
 [ 26  11   3  60 202  46   5]
 [191  53  13  71 114 589   5]
 [ 22   5   0  13   3  12  23]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.30      0.54      0.39       332
           1       0.54      0.37      0.43       374
           2       0.42      0.37      0.40        46
           3       0.73      0.68      0.70       781
           4       0.44      0.57      0.50       353
           5       0.69      0.57      0.62      1036
           6       0.34      0.29      0.32        78

    accuracy                           0.56      3000
   macro avg       0.49      0.48      0.48      3000
weighted avg       0.59      0.56      0.57      3000

0 th epoch dev tnews is below:
0.5378806711088167
********************************confusion_matrix********************************
[[ 18  10   5   0   1   2   2   6   0   3   3   2   0   6   2]
 [  5 125  21   2   4   2   2   7   0  13  29   7   0   7   1]
 [  6  30 157  11   4   0   4  10   7   8   9  17   0   4  13]
 [  0   6  17 157   5   0  10   2   3   6   3  10   0   0   2]
 [  0   5   3   0 167  20  10   8  12   6   9  18   2  12   3]
 [  1   2   0   3  17  72   3   3   2   1   9   2   0   4   0]
 [  1   5   3   3  15   4 156   2   5   8  19  12   0   0   1]
 [  1  25   8   7   9   4   7 102  10   6   5   7   1   7   1]
 [  0   3  12   5 115   5  32  17 108  19   5  14   0   3  18]
 [  0   7   5   1   6   0   3   3   3 130   2  56   0   1   3]
 [  1  12   5   5   7   9   5   7   3   4 102  14   0  11   0]
 [  2   7  13   2   8   4   5   4   2  54  19 161   0   5   0]
 [  0   0   0   0   7   0   0   0   0   0   0   0   5   0   0]
 [  2   5   5   1  23   7   5   4   4   1  11   3   0  78   0]
 [  1   8  20  15   3   0   4   1  13   7   5   2   0   2  97]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.47      0.30      0.37        60
           1       0.50      0.56      0.53       225
           2       0.57      0.56      0.57       280
           3       0.74      0.71      0.73       221
           4       0.43      0.61      0.50       275
           5       0.56      0.61      0.58       119
           6       0.63      0.67      0.65       234
           7       0.58      0.51      0.54       200
           8       0.63      0.30      0.41       356
           9       0.49      0.59      0.53       220
          10       0.44      0.55      0.49       185
          11       0.50      0.56      0.53       286
          12       0.62      0.42      0.50        12
          13       0.56      0.52      0.54       149
          14       0.69      0.54      0.61       178

    accuracy                           0.55      3000
   macro avg       0.56      0.53      0.54      3000
weighted avg       0.56      0.55      0.54      3000

best epoch is: 0 ; with best f1 is: 0.5861772179035456
[ 1000 - th batch : train acc is: 0.6467717717717718 ; train loss is: 0.7522076896957688 ]
[ 2000 - th batch : train acc is: 0.6491370685342671 ; train loss is: 0.7344550759479843 ]

